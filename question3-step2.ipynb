{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f2d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   campaign_id  channel       ctr  conversion_rate       roi  is_profitable\n",
      "0            1   Social  0.045650         0.159836  1.117177           True\n",
      "1            2   Social  0.038944         0.079310  0.376336          False\n",
      "2            3    Email  0.047451         0.140468  0.722115          False\n",
      "3            4  Display  0.030203         0.120247  0.672137          False\n",
      "4            5   Social  0.028806         0.066059  0.449074          False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the csv file \n",
    "\n",
    "file_path = r'C:\\Users\\SUDE\\Downloads\\Question3_CampaignData.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate derived metrics for modeling\n",
    "\n",
    "df['ctr'] = df['clicks'] / df['impressions'].replace(0, pd.NA)\n",
    "df['conversion_rate'] = df['conversions'] / df['clicks'].replace(0, pd.NA)\n",
    "df['roi'] = df['revenue'] / df['spend'].replace(0, pd.NA)\n",
    "df['is_profitable'] = df['revenue'] > df['spend']\n",
    "\n",
    "print(df[['campaign_id', 'channel', 'ctr', 'conversion_rate', 'roi', 'is_profitable']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef68e789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.90\n",
      "Precision: 1.00\n",
      "Recall:    0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Drop rows with missing values (from division by zero earlier)\n",
    "df_clean = df.dropna(subset=['ctr', 'conversion_rate', 'roi'])\n",
    "\n",
    "# Features and target\n",
    "X = df_clean[['ctr', 'conversion_rate', 'roi']]\n",
    "y = df_clean['is_profitable']\n",
    "\n",
    "# Split the data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy:  {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f279ac",
   "metadata": {},
   "source": [
    "In this business problem, the goal is to predict whether a marketing campaign will be profitable. While accuracy is often used as a baseline metric; in real-world situations, it might not always be the most instructive, particularly if the dataset is unbalanced or if the cost of incorrect predictions varies significantly.\n",
    "In our case, we chose to focus on precision and recall alongside accuracy, because predicting profitability incorrectly can lead to significant budget waste or missed opportunities.\n",
    "The model achieved perfect precision (1.00), meaning that every campaign predicted to be profitable actually was. From a business point of view, this is quite appealing because it reduces the risk of wasting money at unsuccessful projects by enabling the marketing team to invest with confidence in the ones the model chooses.\n",
    "\n",
    "However, the recall was 0.75, which means the model missed 25% of the profitable campaigns. This trade-off may be acceptable if the business prioritizes budget safety over opportunity maximization, but if growth is the goal, improving recall could become a focus.\n",
    "\n",
    "Overall, in this context, precision is more important than accuracy, because a single misclassified unprofitable campaign can have a high cost. This precision-recall trade-off would not have been obvious with accuracy alone (90%); for this reason, it is essential to assess a variety of indicators relating to the business impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e8840e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.88\n",
      "Train Precision: 1.00\n",
      "Train Recall:    0.64\n"
     ]
    }
   ],
   "source": [
    "#Overfitting Check\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Training metrics\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "\n",
    "print(f\"Train Accuracy:  {train_accuracy:.2f}\")\n",
    "print(f\"Train Precision: {train_precision:.2f}\")\n",
    "print(f\"Train Recall:    {train_recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cde3454",
   "metadata": {},
   "source": [
    "The training and test performance are very similar across all metrics.\n",
    "In fact, test recall (0.75) is slightly higher than training recall (0.64), which is rare and encouraging.\n",
    "There is no indication of overfitting.\n",
    "The model generalizes well and is not just memorizing the training data which is an rare but positive indicator of generalization. The outcomes are probably reliable when deployed on unseen campaigns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f20df",
   "metadata": {},
   "source": [
    "# Business Application of the Model\n",
    "In a business context, this model can be a valuable decision-support tool for marketing teams tasked with campaign budget allocation. Since the model achieves perfect precision (1.00), any campaign it predicts as profitable can be pursued with high confidence, lowering the risk of funding unsuccessful campaigns by a significant amount.\n",
    "The model’s recall (0.75) shows that it identifies most, but not all, of the profitable opportunities. While some good campaigns may be missed, the trade-off ensures that resources are not wasted — which is especially important when budgets are limited or risk tolerance is low.\n",
    "\n",
    "With a recall of 0.75, the model successfully identifies the majority of profitable campaigns, though it does miss some. This means that while not every opportunity is captured, those that are chosen have a very high chance of being successful.\n",
    "This behavior reflects a conservative prediction strategy, in which the model prioritizes certainty over coverage. Stated differently, it would rather overlook a few successful campaigns than risk recommending a campaign that turns out to be unprofitable.\n",
    "\n",
    "This trade-off is particularly valuable when launching a campaign that fails comes at an enormous cost.\n",
    "The method works well in risk-averse or resource-constrained marketing organizations since within these situations, avoiding errors is more crucial than capturing every opportunity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
